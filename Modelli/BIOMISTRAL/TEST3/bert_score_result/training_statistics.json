{
    "evaluation_frequency": {
        "frequency": 1,
        "period": "epoch"
    },
    "test": {
        "RISPOSTE": {
            "loss": [
                1.0775364637374878,
                0.9533973336219788,
                0.885051965713501
            ],
            "next_token_perplexity": [
                16339.6005859375,
                15970.279296875,
                15602.8876953125
            ],
            "perplexity": [
                31987.64453125,
                31990.23828125,
                31990.359375
            ],
            "sequence_accuracy": [
                0.0,
                0.0,
                0.0
            ],
            "token_accuracy": [
                5.3320720326155424e-05,
                7.692664075875655e-05,
                5.8643763622967526e-05
            ]
        },
        "combined": {
            "loss": [
                1.0775364637374878,
                0.9533973336219788,
                0.885051965713501
            ]
        }
    },
    "training": {
        "RISPOSTE": {
            "loss": [
                1.453224778175354,
                1.0458221435546875,
                0.8570877909660339
            ],
            "next_token_perplexity": [
                17324.310546875,
                16203.77734375,
                15556.8447265625
            ],
            "perplexity": [
                31984.9921875,
                31988.623046875,
                31990.634765625
            ],
            "sequence_accuracy": [
                0.0,
                0.0,
                0.0
            ],
            "token_accuracy": [
                0.00010412957635708153,
                0.00010600963287288323,
                9.603153011994436e-05
            ]
        },
        "combined": {
            "loss": [
                1.453224778175354,
                1.0458221435546875,
                0.8570877909660339
            ]
        }
    },
    "validation": {
        "RISPOSTE": {
            "loss": [
                1.1246905326843262,
                0.9938827157020569,
                0.9267337918281555
            ],
            "next_token_perplexity": [
                16442.109375,
                16059.783203125,
                15710.3251953125
            ],
            "perplexity": [
                31987.765625,
                31987.248046875,
                31985.90625
            ],
            "sequence_accuracy": [
                0.0,
                0.0,
                0.0
            ],
            "token_accuracy": [
                0.00010187122825300321,
                0.00015700924268458039,
                0.00011186157644260675
            ]
        },
        "combined": {
            "loss": [
                1.1246905326843262,
                0.9938827157020569,
                0.9267337918281555
            ]
        }
    }
}